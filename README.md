# ğŸ¤– RAG Research Assistant

> A privacy-first, locally-run Retrieval-Augmented Generation (RAG) system for intelligent conversations with your documents.

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ“– Overview

RAG Research Assistant enables **private, context-aware conversations** with your documents using state-of-the-art retrieval and generation techniques. Everything runs locally on your machineâ€”no data leaves your system.

### What is RAG?

**Retrieval-Augmented Generation** combines:

- ğŸ” **Vector Search**: Find relevant document chunks using semantic similarity
- ğŸ¤– **LLM Generation**: Generate accurate answers grounded in your documents
- ğŸ’¬ **Conversation Memory**: Maintain context across multi-turn conversations

---

## âœ¨ Key Features

| Feature | Description |
| --------- | ------------- |
| ğŸ”’ **100% Private** | All processing happens locallyâ€”no cloud APIs, no data sharing |
| ğŸš€ **Production-Ready** | FastAPI backend with async support and proper error handling |
| ğŸ¨ **Modern UI** | Clean Gradio interface for document management and chat |
| ğŸ“š **Multi-Format** | Support for PDF and text files with intelligent chunking |
| ğŸ§  **Smart Context** | Automatic conversation windowing and summarization |
| ğŸ”„ **Persistent Storage** | ChromaDB vector store and SQLite metadata database |
| ğŸ§ª **Well-Tested** | Comprehensive test suite with pytest |

---

## ğŸ—ï¸ Architecture

```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Gradio UI / REST API           â”‚
â”‚   (User Interface Layer)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     OrchestratorService             â”‚
â”‚   (Business Logic Layer)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DocumentSvc  â”‚ ConversationMgrâ”‚   ...  â”‚
â”‚ (Services)   â”‚  (Services)    â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ChromaDB    â”‚   Ollama     â”‚ SQLite â”‚
â”‚ (VectorStore)â”‚   (LLM)      â”‚  (DB)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Structure

```bash
rag-research-assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/              # FastAPI routes and schemas
â”‚   â”œâ”€â”€ config/           # Configuration and settings
â”‚   â”œâ”€â”€ conversation/     # Chat history and context management
â”‚   â”œâ”€â”€ documents/        # Document ingestion and chunking
â”‚   â”œâ”€â”€ infra/
â”‚   â”‚   â”œâ”€â”€ db/          # SQLite session management
â”‚   â”‚   â”œâ”€â”€ embeddings/  # Sentence Transformers integration
â”‚   â”‚   â”œâ”€â”€ llm/         # Ollama LLM client
â”‚   â”‚   â””â”€â”€ vectorstore/ # ChromaDB wrapper
â”‚   â”œâ”€â”€ orchestrator/    # Main business logic coordinator
â”‚   â””â”€â”€ utils/           # Logging and utilities
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ gradio_app.py    # Production UI (use this)
â”‚   â””â”€â”€ main.py          # UI experimentation sandbox
â”œâ”€â”€ tests/               # Pytest test suite
â”œâ”€â”€ data/                # Auto-created: stores DB and vectors
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“‹ Prerequisites

Before you begin, ensure you have:

- **Python 3.11 or higher** ([Download](https://www.python.org/downloads/))
- **Ollama** installed and running ([Installation Guide](https://ollama.ai/download))
- **Git** for cloning the repository

### Verify Ollama Installation

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Should return a JSON response with available models
```

---

## ğŸš€ Quick Start

### 1. Clone and Install Dependencies

```bash
# Clone the repository
git clone https://github.com/dsbarik/rag-research-assistant.git
cd rag-research-assistant

# Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Download the LLM Model

```bash
# Pull the default model (llama3.2)
ollama pull llama3.2

# Verify the model is available
ollama list
```

### 3. Start the Backend API

Open a terminal and run:

```bash
fastapi dev src/api/main.py
```

âœ… API will be available at: **<http://localhost:8000>**  
ğŸ“š Interactive docs at: **<http://localhost:8000/docs>**

### 4. Start the Gradio UI

Open a **new terminal** (keep the API running) and run:

```bash
python ui/gradio_app.py
```

âœ… Web interface will open at: **<http://localhost:7860>**

---

## ğŸ’¡ Usage Guide

### Using the Gradio UI

1. **Upload Documents**
   - Navigate to the "ğŸ“‚ Knowledge Base" tab
   - Click "Select PDF Files" and choose your documents
   - Click "ğŸš€ Ingest Document" to process them

2. **Chat with Your Documents**
   - Switch to the "ğŸ’¬ Chat" tab
   - Ask questions about your uploaded documents
   - The system will retrieve relevant context and generate answers

3. **Manage Documents**
   - View all uploaded documents in the table
   - Delete documents you no longer need
   - Refresh the list to see updates

### Using the REST API

#### Upload a Document

```bash
curl -X POST "http://localhost:8000/api/v1/ingest" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@/path/to/document.pdf"
```

**Response:**

```json
{
  "status": "success",
  "document_id": 1,
  "chunks_processed": 42
}
```

#### Chat with Context

```bash
curl -X POST "http://localhost:8000/api/v1/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What are the main findings?",
    "conversation_id": null
  }'
```

**Response:**

```json
{
  "conversation_id": 1,
  "response": "Based on the documents, the main findings are...",
  "sources": [
    {"filename": "document.pdf", "chunk_id": "doc_1_chunk_3"}
  ]
}
```

#### List All Documents

```bash
curl -X GET "http://localhost:8000/api/v1/documents"
```

#### Delete a Document

```bash
curl -X DELETE "http://localhost:8000/api/v1/documents/1"
```

---

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file in the project root (optional):

```env
# LLM Configuration
LLM_MODEL_NAME=llama3.2
OLLAMA_BASE_URL=http://localhost:11434

# Paths (defaults to ./data/)
DATA_DIR=./data
DOCUMENTS_DIR=./data/documents
VECTOR_STORE_DIR=./data/vector_store
DATABASE_PATH=./data/documents.db
```

### Changing the LLM Model

Edit `src/config/settings.py`:

```python
LLM_MODEL_NAME = "llama3.2"  # Change to any Ollama model
```

Available models: `llama3.2`, `mistral`, `codellama`, etc. ([Full list](https://ollama.ai/library))

---

## ğŸ§ª Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src tests/

# Run specific test file
pytest tests/test_orchestrator.py -v
```

---

## ğŸ”§ Troubleshooting

### Issue: "Connection refused" when starting API

**Solution:** Ensure Ollama is running:

```bash
# Check Ollama status
curl http://localhost:11434/api/tags

# If not running, start Ollama
ollama serve
```

### Issue: "Module not found: sentence_transformers"

**Solution:** Install the missing dependency:

```bash
pip install sentence-transformers
```

### Issue: Documents not being ingested

**Possible causes:**

- File is a duplicate (check hash in database)
- Unsupported file format (only PDF and TXT supported)
- File is corrupted or empty

**Debug:**

```bash
# Check API logs for detailed error messages
# Check data/documents/ directory for uploaded files
```

### Issue: Slow response times

**Solutions:**

- Use a smaller/faster LLM model (e.g., `llama3.2:1b`)
- Reduce chunk retrieval limit in `orchestrator/service.py`
- Ensure Ollama has sufficient RAM allocated

---

## ğŸ—ºï¸ Roadmap

This is an **ongoing project** with planned enhancements:

- [ ] **Multi-Agent System** (`agents/`) - Specialized agents for different tasks
- [ ] **Knowledge Graph Integration** (`kg/`) - Entity extraction and graph-based verification
- [ ] **Advanced Retrieval** (`retrieval/`) - Hybrid search, re-ranking, query expansion
- [ ] **Explainability** (`explanation/`) - Visualize retrieval and generation process
- [ ] **FAISS Support** - Alternative vector store for larger datasets
- [ ] **More File Formats** - DOCX, Markdown, HTML support
- [ ] **Streaming Responses** - Real-time token streaming in UI
- [ ] **Multi-User Support** - User authentication and document isolation

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **[Ollama](https://ollama.ai/)** - Local LLM inference
- **[ChromaDB](https://www.trychroma.com/)** - Vector database
- **[Sentence Transformers](https://www.sbert.net/)** - Embedding models
- **[FastAPI](https://fastapi.tiangolo.com/)** - Modern web framework
- **[Gradio](https://gradio.app/)** - UI framework

---

## ğŸ“ Support

- ğŸ“§ Email: <your-email@example.com>
- ğŸ› Issues: [GitHub Issues](https://github.com/dsbarik/rag-research-assistant/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/dsbarik/rag-research-assistant/discussions)

---

**Built with â¤ï¸ for privacy-conscious researchers and developers**
